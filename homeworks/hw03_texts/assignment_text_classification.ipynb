{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "jNtLJlW4v5VF"
   },
   "source": [
    "## Домашнее задание №3\n",
    "\n",
    "В данном задании мы будем работать над задачей классификации последовательностей (текстов) с использованием различных методов векторизации слов. Также обратимся к классическим алгоритмам и нейронным сетям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "grIwIEWAv5VK"
   },
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "out_dict = dict()\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# __________end of block__________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "CijSj69Ov5VN"
   },
   "source": [
    "### Предобработка текста и токенизация\n",
    "\n",
    "Предобработка практически аналогична рассмотренной на предшествующем занятии. Библиотека `nltk` [link](https://www.nltk.org) широко используется при обработке текстов. По ссылке выше можно найти ее развернутое описание и документацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "df = pd.read_csv(\n",
    "    'https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv',\n",
    "    delimiter='\\t',\n",
    "    header=None\n",
    ")\n",
    "texts_train = df[0].values[:5000]\n",
    "y_train = df[1].values[:5000]\n",
    "texts_test = df[0].values[5000:]\n",
    "y_test = df[1].values[5000:]\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tokenizer = WordPunctTokenizer()\n",
    "preprocess = lambda text: ' '.join(tokenizer.tokenize(text.lower()))\n",
    "\n",
    "text = 'How to be a grown-up at work: replace \"I don\\'t want to do that\" with \"Ok, great!\".'\n",
    "print(\"before:\", text,)\n",
    "print(\"after:\", preprocess(text),)\n",
    "\n",
    "texts_train = [preprocess(text) for text in texts_train]\n",
    "texts_test = [preprocess(text) for text in texts_test]\n",
    "\n",
    "# Small check that everything is done properly\n",
    "assert texts_train[5] ==  'campanella gets the tone just right funny in the middle of sad in the middle of hopeful'\n",
    "assert texts_test[74] == 'poetry in motion captured on film'\n",
    "assert len(texts_test) == len(y_test)\n",
    "# __________end of block__________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующие функции помогут вам с визуализацией процесса обучения сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "def plot_train_process(train_loss, val_loss, train_accuracy, val_accuracy, title_suffix=''):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    axes[0].set_title(' '.join(['Loss', title_suffix]))\n",
    "    axes[0].plot(train_loss, label='train')\n",
    "    axes[0].plot(val_loss, label='validation')\n",
    "    axes[0].legend()\n",
    "\n",
    "    axes[1].set_title(' '.join(['Validation accuracy', title_suffix]))\n",
    "    axes[1].plot(train_accuracy, label='train')\n",
    "    axes[1].plot(val_accuracy, label='validation')\n",
    "    axes[1].legend()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_and_save_results(model, model_name, X_train, X_test, y_train, y_test, out_dict):\n",
    "    for data_name, X, y, model in [\n",
    "    ('train', X_train, y_train, model),\n",
    "    ('test', X_test, y_test, model)\n",
    "    ]:\n",
    "        if isinstance(model, BaseEstimator):\n",
    "            proba = model.predict_proba(X)[:, 1]\n",
    "        elif isinstance(model, nn.Module):\n",
    "            proba = model(X).detach().cpu().numpy()[:, 1]\n",
    "        else:\n",
    "            raise ValueError('Unrecognized model type')\n",
    "            \n",
    "        auc = roc_auc_score(y, proba)\n",
    "\n",
    "        out_dict['{}_{}'.format(model_name, data_name)] = auc\n",
    "        plt.plot(*roc_curve(y, proba)[:2], label='%s AUC=%.4f' % (data_name, auc))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], '--', color='black',)\n",
    "    plt.legend(fontsize='large')\n",
    "    plt.title(model_name)\n",
    "    plt.grid()\n",
    "    return out_dict\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Повторение: основные понятия в глубоком обучении\n",
    "\n",
    "__Слой (layer)__ – некоторое преобразование над исходными данными. Простейший пример: линейный слой, являющийся линейным преобразованием над входящими данными (т.е. просто преобразование $WX +b$, как и в линейной регрессии).\n",
    "\n",
    "__Функция активации (activation function)__ – нелинейное преобразование, применяется ко всем данным пришедшим на вход поэлементно. Благодаря функциям активации нейронные сети делают *нелинейные преобразования* над исходными признаками, тем самым порождая более информативное признаковое описание.\n",
    "\n",
    "__Нейронная сеть (neural network)__ – композиция линейных и нелинейных преобразований (как правило, представимая в виде последовательности слоев и функций активации). Изучением нейронных сетей и их применимости в различных задачах занимается глубокое обучение (Deep Learning). В большинстве случаев вся нейронная сеть является одной сложной *дифференцируемой* функцией, что накладывает ограничения на возможность использование тех или иных преобразований.\n",
    "\n",
    "__Регуляризация (regularization)__ – механизм наложения ограничений на решение в зависимости от экспертных знаний и/или априорных предположений о решаемой задаче. Может быть представлена в форме дополнительного члена в функции потерь (например, $L1$ или $L2$ регуляризация), в форме ограничений на структуру модели (`Dropout`, `Batch Normalization`) и в других формах.\n",
    "\n",
    "__Функция потерь (loss function)__ – функция потерь, оценивающая качество полученного предсказания. Как правило, от функции потерь требуется свойство дифференцируемости (т.к. настройка параметров сети происходит методом *обратного распространения ошибки*). В некоторых случаях (например, в обучении с подкреплением) используются и недифференцируемые функции потерь/награды. Их использование требует доработки механизма обучения нейронных сетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Работа с текстами и последовательностями\n",
    "\n",
    "* __Последовательности__. Данные – наборы значений, на которых задано отношение порядка. Значения могут быть дискретными (например, ДНК), или же могут принимать значения из непрерывного интервала (временной ряд энергопотребления дата центра). Перестановка значений приводит к потере информации. Нельзя нарушать отношение порядка (тестирование на прошлом, обучение на будущем).\n",
    "\n",
    "* __Тексты__. Данные – наборы слов/символов. По факту являются последовательностями значений из конечного алфавита, но обладают достаточно строгой внутренней структурой ввиду существования грамматики.\n",
    "\n",
    "В работе с естественным языком (в виде текста в первую очередь), а также в работе с последовательностями себя отлично зарекомендовали рекуррентные сети и сети, основанные на механизме внимания (attention mechanism), подобные модели Transformer, предложенной в 2017 году в работе Attention is all you need. Как рекуррентные, так и transformer-like модели учитывают зависимость элементов последовательности друг от друга (и в целом наличие порядка), что позволяет им порождать информативные признаковые представления автоматически (подобно сверточным сетям при работе с изображениями). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "wgd0Mlzsv5VO"
   },
   "source": [
    "### Задача №1. Мешок слов.\n",
    "\n",
    "Воспользуйтесь классическим подходом к векторизации текстов: мешком слов. Для этого вы можете как воспользоваться `CountVectorizer` из `sklearn`, так и самостоятельно реализованный вариант.\n",
    "\n",
    "Мешок слов сопоставляет каждому слову из словаря уникальный индекс (номер слова в словаре) и строит итоговый вектор для текста как набор счетчиков каждого слова из словаря. Этот подход эквивалентен построению суммы `one-hot` векторов для каждого из слов в тексте.\n",
    "\n",
    "#### __One-hot кодирование__. \n",
    "Каждому слову в языке можно сопоставить уникальный индекс и поставить слову в соответствие вектор, где нули стоят на всех местах, кроме заданного индекса. Такой подход называется one-hot кодированием. Пример такого кодирования можно увидеть ниже.\n",
    "\n",
    "*Пример: слово \"собака\" находится на третьем месте в словаре из 5 слов. Тогда ему будет соответствовать вектор `[0, 0, 1, 0, 0]`. Слово \"кошка\" стоит на втором месте, ему соответствует вектор `[0, 1, 0, 0, 0]`. Слово \"кот\" – на четвёртом, ему соответствует вектор `[0, 0, 0, 1, 0]`.*\n",
    "\n",
    "\n",
    "\n",
    "Обращаем ваше внимание, в части 1 используется лишь `k` наиболее часто встречаемых слов из обучающей части выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZNHFsVuPv5VP",
    "outputId": "55ed5eb3-7442-40ae-accd-5dc595335321"
   },
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "k = min(10000, len(set(' '.join(texts_train).split())))\n",
    "\n",
    "counts = Counter(' '.join(texts_train).split())\n",
    "\n",
    "bow_vocabulary = [key for key, val in counts.most_common(k)]\n",
    "\n",
    "\n",
    "def text_to_bow(text):\n",
    "    \"\"\" convert text string to an array of token counts. Use bow_vocabulary. \"\"\"\n",
    "    sent_vec = np.zeros(len(bow_vocabulary))\n",
    "    counts = Counter(text.split())\n",
    "    for i, token in enumerate(bow_vocabulary):\n",
    "        if token in counts:\n",
    "            sent_vec[i] = counts[token]\n",
    "    return np.array(sent_vec, 'float32')\n",
    "\n",
    "X_train_bow = np.stack(list(map(text_to_bow, texts_train)))\n",
    "X_test_bow = np.stack(list(map(text_to_bow, texts_test)))\n",
    "\n",
    "# Small check that everything is done properly if you are using local bow implementation\n",
    "k_max = len(set(' '.join(texts_train).split()))\n",
    "assert X_train_bow.shape == (len(texts_train), min(k, k_max))\n",
    "assert X_test_bow.shape == (len(texts_test), min(k, k_max))\n",
    "assert np.all(X_train_bow[5:10].sum(-1) == np.array([len(s.split()) for s in  texts_train[5:10]]))\n",
    "assert len(bow_vocabulary) <= min(k, k_max)\n",
    "assert X_train_bow[65, bow_vocabulary.index('!')] == texts_train[65].split().count('!')\n",
    "\n",
    "\n",
    "bow_model = LogisticRegression(max_iter=1500).fit(X_train_bow, y_train)\n",
    "\n",
    "out_dict = visualize_and_save_results(bow_model, 'bow_log_reg_sklearn', X_train_bow, X_test_bow, y_train, y_test, out_dict)\n",
    "# __________end of block__________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "gSg1inPqv5VR"
   },
   "source": [
    "Результаты неплохие, но явно видно переобучение. Этот вывод можно сделать судя по значительному превосходству качества (AUC ROC) на train выборке относительно test. Более того, на обучающей выборке качество стремится к единице, в то время как на отложенной – значительно ниже, т.е. модель уловила множество зависимостей, свойственных лишь обучающей выборке. Базово проблема переобучения рассматривалась в предыдущих занятиях и еще не раз встретится на курсе в дальнейшем.\n",
    "\n",
    "В данной задаче с переобучением мы разберемся в дальнейшем. Сейчас же реализуйте решение на основе логистической регрессии, но уже используя PyTorch. В результате вам должна быть доступна обученная модель, предсказывающая вероятности для двух классов. Качество на тестовой выборке должно не уступать логистической регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YRN4ofOgv5VR",
    "outputId": "3e81e921-5166-4612-8476-f4bb041ee6e1"
   },
   "outputs": [],
   "source": [
    "model = # your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "HLx_3tOCv5VR"
   },
   "source": [
    "Не забывайте о функциях потерь: `nn.CrossEntropyLoss` объединяет в себе `LogSoftMax` и `NLLLoss`. Также не забывайте о необходимости перенести тензоры на используемый `device`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W7dcCGLsv5VS"
   },
   "outputs": [],
   "source": [
    "loss_function = # your code here\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CK7iew17v5VS"
   },
   "outputs": [],
   "source": [
    "X_train_bow_torch = # your code here\n",
    "X_test_bow_torch = # your code here\n",
    "\n",
    "y_train_torch = # your code here\n",
    "y_test_torch = # your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция ниже поможет с обучением модели. Часть кода необходимо реализовать самостоятельно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K4GGcyXYv5VT"
   },
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    opt,\n",
    "    X_train_torch,\n",
    "    y_train_torch,\n",
    "    X_val_torch,\n",
    "    y_val_torch,\n",
    "    n_iterations=500,\n",
    "    batch_size=32,\n",
    "    show_plots=True,\n",
    "    eval_every=50\n",
    "):\n",
    "    train_loss_history = []\n",
    "    train_acc_history = []\n",
    "    val_loss_history = []\n",
    "    val_acc_history = []\n",
    "\n",
    "    local_train_loss_history = []\n",
    "    local_train_acc_history = []\n",
    "    for i in range(n_iterations):\n",
    "\n",
    "        # sample batch_size random observations\n",
    "        ix = np.random.randint(0, len(X_train_torch), batch_size)\n",
    "        x_batch = X_train_torch[ix]\n",
    "        y_batch = y_train_torch[ix]\n",
    "\n",
    "        # predict log-probabilities or logits\n",
    "        y_predicted = # your code here\n",
    "        \n",
    "        # compute loss, just like before\n",
    "        loss = # your code here\n",
    "\n",
    "        # compute gradients\n",
    "        # your code here\n",
    "\n",
    "        # Adam step\n",
    "        # your code here\n",
    "\n",
    "        # clear gradients\n",
    "        # your code here\n",
    "\n",
    "        local_train_loss_history.append(loss.item())\n",
    "        local_train_acc_history.append(\n",
    "            accuracy_score(\n",
    "                y_batch.to('cpu').detach().numpy(),\n",
    "                y_predicted.to('cpu').detach().numpy().argmax(axis=1)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if i % eval_every == 0:\n",
    "            train_loss_history.append(np.mean(local_train_loss_history))\n",
    "            train_acc_history.append(np.mean(local_train_acc_history))\n",
    "            local_train_loss_history, local_train_acc_history = [], []\n",
    "\n",
    "            predictions_val = model(X_val_torch)\n",
    "            val_loss_history.append(loss_function(predictions_val, y_val_torch).to('cpu').detach().item())\n",
    "\n",
    "            acc_score_val = accuracy_score(y_val_torch.cpu().numpy(), predictions_val.to('cpu').detach().numpy().argmax(axis=1))\n",
    "            val_acc_history.append(acc_score_val)\n",
    "\n",
    "            if show_plots:\n",
    "                display.clear_output(wait=True)\n",
    "                plot_train_process(train_loss_history, val_loss_history, train_acc_history, val_acc_history)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 584
    },
    "id": "TILA0_Aiv5VU",
    "outputId": "0bb9db5b-82d8-486b-b320-6021d4f37459"
   },
   "outputs": [],
   "source": [
    "bow_nn_model = train_model(model, opt, X_train_bow_torch, y_train_torch, X_test_bow_torch, y_test_torch, n_iterations=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "out_dict = visualize_and_save_results(bow_nn_model, 'bow_nn_torch', X_train_bow_torch, X_test_bow_torch, y_train, y_test, out_dict)\n",
    "\n",
    "assert out_dict['bow_log_reg_sklearn_test'] - out_dict['bow_nn_torch_test'] < 0.01, 'AUC ROC on test data should be close to the sklearn implementation'\n",
    "# __________end of block__________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEt4byBxv5VU"
   },
   "source": [
    "А теперь повторите процедуру обучения выше, но для различных значений `k` – размера словаря. В список results сохраните `AUC ROC` на тестовой части выборки для модели, обученной со словарем размера `k`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "jq9qxODpv5VU",
    "outputId": "47cf61ce-533c-46f7-b0c5-6f6f670018cb"
   },
   "outputs": [],
   "source": [
    "vocab_sizes_list = np.arange(100, 5800, 700)\n",
    "results = []\n",
    "\n",
    "for k in vocab_sizes_list:\n",
    "    # your code here\n",
    "    predicted_probas_on_test_for_k_sized_dict = None\n",
    "    assert predicted_probas_on_test_for_k_sized_dict is not None\n",
    "    auc = roc_auc_score(y_test, predicted_probas_on_test_for_k_sized_dict)\n",
    "    results.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert len(results) == len(vocab_sizes_list), 'Check the code above'\n",
    "assert min(results) >= 0.65, 'Seems like the model is not trained well enough'\n",
    "assert results[-1] > 0.84, 'Best AUC ROC should not be lower than 0.84'\n",
    "\n",
    "plt.plot(vocab_sizes_list, results)\n",
    "plt.xlabel('num of tokens')\n",
    "plt.ylabel('AUC')\n",
    "plt.grid()\n",
    "\n",
    "out_dict['bow_k_vary'] = results\n",
    "# __________end of block__________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "iA_3nEyHv5VV"
   },
   "source": [
    "### Задача №2: Использование TF-iDF признаков.\n",
    "\n",
    "Для векторизации текстов также можно воспользоваться TF-iDF. Это позволяет исключить из рассмотрения многие слова, не оказывающие значимого влияния при оценке непохожести текстов.\n",
    "\n",
    "Подробнее про TF-iDF можно почитать, например, [здесь](https://towardsdatascience.com/tf-idf-for-document-ranking-from-scratch-in-python-on-real-world-dataset-796d339a4089).\n",
    "Там же можно почитать о его самостоятельной реализации.\n",
    "\n",
    "Ваша задача: векторизовать тексты используя TF-iDF (или `TfidfVectorizer` из `sklearn`, или реализовав его самостоятельно) и построить классификатор с помощью PyTorch, аналогичный задаче №1.\n",
    "\n",
    "Затем также оцените качество классификации по AUC ROC для различных размеров словаря.\n",
    "\n",
    "Качество классификации должно быть не ниже 0.86 AUC ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "THMktAtZNAqP"
   },
   "outputs": [],
   "source": [
    "X_train_tfidf = # your code here\n",
    "X_test_tfidf = # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xHbOlK1dyws8",
    "outputId": "d19d123a-9232-4df5-b743-29e2181144d2"
   },
   "outputs": [],
   "source": [
    "model = # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 584
    },
    "id": "fioSJacvjr2v",
    "outputId": "d5b10947-9ee2-48d9-f553-7dfd9871ec20"
   },
   "outputs": [],
   "source": [
    "loss_function = # your code here\n",
    "opt = # your code here\n",
    "\n",
    "model_tf_idf = train_model(model, opt, X_train_tfidf_torch, y_train_torch, X_test_tfidf_torch, y_test_torch, n_iterations=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "out_dict = visualize_and_save_results(model_tf_idf, 'tf_idf_nn_torch', X_train_tfidf_torch, X_test_tfidf_torch, y_train, y_test, out_dict)\n",
    "\n",
    "assert out_dict['tf_idf_nn_torch_test'] >= out_dict['bow_nn_torch_test'], 'AUC ROC on test data should be better or close to BoW for TF-iDF features'\n",
    "# __________end of block__________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично задаче №1 повторите процедуру обучения для различных значений `k` – размера словаря и сохраните `AUC ROC` на тестовой части выборки в список `results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_sizes_list = np.arange(100, 5800, 700)\n",
    "results = []\n",
    "\n",
    "for k in vocab_sizes_list:\n",
    "    # your code here\n",
    "    predicted_probas_on_test_for_k_sized_dict = None\n",
    "    assert predicted_probas_on_test_for_k_sized_dict is not None\n",
    "    auc = roc_auc_score(y_test, predicted_probas_on_test_for_k_sized_dict)\n",
    "    results.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert len(results) == len(vocab_sizes_list), 'Check the code above'\n",
    "assert min(results) >= 0.65, 'Seems like the model is not trained well enough'\n",
    "assert results[-1] > 0.85, 'Best AUC ROC for TF-iDF should not be lower than 0.84'\n",
    "\n",
    "plt.plot(vocab_sizes_list, results)\n",
    "plt.xlabel('num of tokens')\n",
    "plt.ylabel('AUC')\n",
    "plt.grid()\n",
    "\n",
    "out_dict['tf_idf_k_vary'] = results\n",
    "# __________end of block__________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Uo-aLAItv5VW"
   },
   "source": [
    "### Задача №3: Сравнение с Наивным Байесовским классификатором.\n",
    "\n",
    "Классические модели все еще способны показать хороший результат во многих задачах. Обучите наивный байесовский классификатор на текстах, векторизованных с помощью BoW и TF-iDF и сравните результаты с моделями выше.\n",
    "\n",
    "*Комментарий: обращаем ваше внимание, необходимо выбрать подходящее к данной задаче априорное распределение для признаков, т.е. выбрать верную версию классификатора из `sklearn`: `GaussianNB`, `MultinomialNB`, `ComplementNB`, `BernoulliNB`, `CategoricalNB`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "f5Hy-mJnW5Hc",
    "outputId": "e1ebb8e4-cec1-4d49-bc9b-28eff714ea78"
   },
   "outputs": [],
   "source": [
    "clf_nb_bow = # your code here\n",
    "\n",
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "out_dict = visualize_and_save_results(clf_nb_bow, 'bow_nb_sklearn', X_train_bow, X_test_bow, y_train, y_test, out_dict)\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_nb_tfidf = # your code here\n",
    "\n",
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "out_dict = visualize_and_save_results(clf_nb_tfidf, 'tf_idf_nb_sklearn', X_train_tfidf, X_test_tfidf, y_train, y_test, out_dict)\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert out_dict['tf_idf_nb_sklearn_test'] > out_dict['bow_nb_sklearn_test'],' TF-iDF results should be better'\n",
    "assert out_dict['tf_idf_nb_sklearn_test'] > 0.86, 'TF-iDF Naive Bayes score should be above 0.86'\n",
    "# __________end of block__________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "tvqsaoedv5VW"
   },
   "source": [
    "### Задача №4: Использование предобученных эмбеддингов\n",
    "#### __Построение эмбеддингов с помощью word2vec__.\n",
    "Предложенные выше подходы обладают существенными недостатками: они не учитывает смысл слов при сопоставлении вектора каждому из них. Поэтому расстояние между one-hot векторами для слов \"кошка\" и \"собака\", для слов \"кошка\" и \"самолет\" или для слов \"кошка\" и \"кот\" будет одинаковой. Для владеющего языком человека разница между словами очевидна, как и то, что \"кошка\" и \"кот\" гораздо ближе друг к другу по смыслу, чем \"кошка\" и \"самолет\". При построении информативного векторного представления также хотелось бы установить смысловую близость слов.\n",
    "\n",
    "С этим может помочь простая мысль (озвученная в различных формах множество раз): __слово в значительной мере определяется контекстом, в котором оно встречается__. На основании чего можно сделать простой вывод: для некоторых слов более характерен один контекст, а для других – другой. Именно на этой идее и построен word2vec (как и многие другие эмбеддинги).\n",
    "\n",
    "По слову можно научиться предсказывать контекст, в котором оно встречается. Конечно, результат не будет идеально точным. Но если модель делает предсказания лучше, чем случайным образом, значит, она улавливает какую-то связь. И тогда внутреннее представление модели для каждого слова и может использоваться в качестве искомого векторного представления, причем и в других задачах.\n",
    "\n",
    "\n",
    "Формулировка гипотезы выше (слово значительно связано с контекстом) позволяет использовать в качестве обучающей выборки все множество текстов для выбранного языка. Собрание сочинений классиков, статьи в энциклопедии, новостные заметки – все это становится обучающей выборкой. И векторные представления, полученные на основе данных текстов позволяют улавливать связь между этими словами.\n",
    "![](https://ruder.io/content/images/size/w2000/2016/04/word_embeddings_colah.png)\n",
    "*Image source: https://ruder.io/word-embeddings-1/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной части для получения предобученных векторных представлений  мы воспользуемся предобученными эмбеддингами из библиотеки `gensim`. В нем доступно несколько эмбеддингов, предобученных на различных корпусах текстов. Полный список можно найти [здесь](https://radimrehurek.com/gensim/models/word2vec.html#pretrained-models). Напоминаем, что лучше использовать те эмбеддинги, которые были обучены на текстах похожей структуры.\n",
    "\n",
    "Ваша задача: обучить модель (достаточно логистической регрессии или же двуслойной неронной сети), используя усредненный эмбеддинг для всех токенов в отзыве, добиться качества не хуже, чем с помощью BoW/TF-iDF и снизить степень переобучения (разницу между AUC ROC на обучающей и тестовой выборках)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DP5td5Ivv5VW",
    "outputId": "8278e048-9676-4ba2-d76b-608f2b321bad"
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "gensim_embedding_model = api.load(# your code here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sC8wyIqY6Ce9"
   },
   "outputs": [],
   "source": [
    "def text_to_average_embedding(text, gensim_embedding_model):\n",
    "    # your code here\n",
    "    return embedding_for_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yZ8-03TIJNjz"
   },
   "outputs": [],
   "source": [
    "X_train_emb = [text_to_average_embedding(text, gensim_embedding_model) for text in texts_train]\n",
    "X_test_emb = [text_to_average_embedding(text, gensim_embedding_model) for text in texts_test]\n",
    "\n",
    "assert len(X_train_emb[0]) == gensim_embedding_model.vector_size, 'Seems like the embedding shape is wrong'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Gw5B5JJ7Z1y"
   },
   "outputs": [],
   "source": [
    "X_train_emb_torch = # your code here\n",
    "X_test_emb_torch = # your code here\n",
    "\n",
    "y_train_torch = # your code here\n",
    "y_test_torch = # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6yQ2zL0bjgcD",
    "outputId": "d0f09b05-16a5-4027-d9ee-2a537621496a"
   },
   "outputs": [],
   "source": [
    "model = # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 584
    },
    "id": "IP-Be_CRHI1f",
    "outputId": "9f6b1aca-a550-48c1-b041-29d43c239138"
   },
   "outputs": [],
   "source": [
    "loss_function = # your code here\n",
    "opt = # your code here\n",
    "\n",
    "model = train_model(model, opt, X_train_emb_torch, y_train_torch, X_test_emb_torch, y_test_torch, n_iterations=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "out_dict = visualize_and_save_results(model, 'emb_nn_torch', X_train_emb_torch, X_test_emb_torch, y_train, y_test, out_dict)\n",
    "assert out_dict['emb_nn_torch_test'] > 0.87, 'AUC ROC on test data should be better than 0.86'\n",
    "assert out_dict['emb_nn_torch_train'] - out_dict['emb_nn_torch_test'] < 0.1, 'AUC ROC on test and train data should not be different more than by 0.1'\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы:\n",
    "_Сформулируйте выводы о каждом из подходов к векторизации слов, а также о работоспособности моделей (Naive Bayes, Logistic Regression, etc.)_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "hohtOwysavfv"
   },
   "source": [
    "### Сдача задания\n",
    "Запустите код ниже для генерации посылки и сдайте на проверку в контест файл `submission_dict_hw03.npy`, а также загрузите заполненный ноутбук с вашими выводами по каждой из частей в форму для сдачи задания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o-lidlX4a_mM"
   },
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "np.save('submission_dict_hw03.npy', out_dict, allow_pickle=True)\n",
    "print('File saved to `submission_dict_hw03.npy`')\n",
    "# __________end of block__________"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP_hw01_texts.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Py3 Research",
   "language": "python",
   "name": "py3_research_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
