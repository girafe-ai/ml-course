{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNtLJlW4v5VF"
   },
   "source": [
    "## Assignment 01\n",
    "\n",
    "В данном задании мы рассмотрим задачу классификации текстов. Для достижения лучших результатов воспользуемся информативными призанковыми описаниями для слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "grIwIEWAv5VK"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neychev/miniforge3/envs/py3_research/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "out_dict = dict()\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CijSj69Ov5VN"
   },
   "source": [
    "### Предобработка текста и токенизация\n",
    "\n",
    "Предобработка практически аналогична рассмотренной на лекции. Библиотека `nltk` [link](https://www.nltk.org) широко используется при обработке текстов. По ссылке выше можно найти ее развернутое описание и документацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: How to be a grown-up at work: replace \"I don't want to do that\" with \"Ok, great!\".\n",
      "after: how to be a grown - up at work : replace \" i don ' t want to do that \" with \" ok , great !\".\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "df = pd.read_csv(\n",
    "    'https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv',\n",
    "    delimiter='\\t',\n",
    "    header=None\n",
    ")\n",
    "texts_train = df[0].values[:5000]\n",
    "y_train = df[1].values[:5000]\n",
    "texts_test = df[0].values[5000:]\n",
    "y_test = df[1].values[5000:]\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tokenizer = WordPunctTokenizer()\n",
    "preprocess = lambda text: ' '.join(tokenizer.tokenize(text.lower()))\n",
    "\n",
    "text = 'How to be a grown-up at work: replace \"I don\\'t want to do that\" with \"Ok, great!\".'\n",
    "print(\"before:\", text,)\n",
    "print(\"after:\", preprocess(text),)\n",
    "\n",
    "texts_train = [preprocess(text) for text in texts_train]\n",
    "texts_test = [preprocess(text) for text in texts_test]\n",
    "\n",
    "# Small check that everything is done properly\n",
    "assert texts_train[5] ==  'campanella gets the tone just right funny in the middle of sad in the middle of hopeful'\n",
    "assert texts_test[74] == 'poetry in motion captured on film'\n",
    "assert len(texts_test) == len(y_test)\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующие функции помогут вам с визуализацией процесса обучения сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "def plot_train_process(train_loss, val_loss, train_accuracy, val_accuracy, title_suffix=''):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    axes[0].set_title(' '.join(['Loss', title_suffix]))\n",
    "    axes[0].plot(train_loss, label='train')\n",
    "    axes[0].plot(val_loss, label='validation')\n",
    "    axes[0].legend()\n",
    "\n",
    "    axes[1].set_title(' '.join(['Validation accuracy', title_suffix]))\n",
    "    axes[1].plot(train_accuracy, label='train')\n",
    "    axes[1].plot(val_accuracy, label='validation')\n",
    "    axes[1].legend()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_and_save_results(model, model_name, X_train, X_test, y_train, y_test, out_dict):\n",
    "    for data_name, X, y, model in [\n",
    "    ('train', X_train, y_train, model),\n",
    "    ('test', X_test, y_test, model)\n",
    "    ]:\n",
    "        if isinstance(model, BaseEstimator):\n",
    "            proba = model.predict_proba(X)[:, 1]\n",
    "        elif isinstance(model, nn.Module):\n",
    "            proba = model(X).detach().cpu().numpy()[:, 1]\n",
    "        else:\n",
    "            raise ValueError('Unrecognized model type')\n",
    "            \n",
    "        auc = roc_auc_score(y, proba)\n",
    "\n",
    "        out_dict['{}_{}'.format(model_name, data_name)] = auc\n",
    "        plt.plot(*roc_curve(y, proba)[:2], label='%s AUC=%.4f' % (data_name, auc))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], '--', color='black',)\n",
    "    plt.legend(fontsize='large')\n",
    "    plt.title(model_name)\n",
    "    plt.grid()\n",
    "    return out_dict\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgd0Mlzsv5VO"
   },
   "source": [
    "### Задача №1. Мешок слов.\n",
    "\n",
    "Воспользуйтесь классическим подходом к векторизации текстов: мешком слов. Для этого можно как воспользоваться `CountVectorizer` из `sklearn`, так и самостоятельно реализовать ее. Обращаем ваше внимание, в данной задаче используется лишь `k` наиболее часто встречаемых слов из обучающей части выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZNHFsVuPv5VP",
    "outputId": "55ed5eb3-7442-40ae-accd-5dc595335321"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "k = min(10000, len(set(' '.join(texts_train).split())))\n",
    "\n",
    "counts = Counter(' '.join(texts_train).split())\n",
    "\n",
    "bow_vocabulary = [key for key, val in counts.most_common(k)]\n",
    "\n",
    "\n",
    "def text_to_bow(text):\n",
    "    \"\"\" convert text string to an array of token counts. Use bow_vocabulary. \"\"\"\n",
    "    sent_vec = np.zeros(len(bow_vocabulary))\n",
    "    counts = Counter(text.split())\n",
    "    for i, token in enumerate(bow_vocabulary):\n",
    "        if token in counts:\n",
    "            sent_vec[i] = counts[token]\n",
    "    return np.array(sent_vec, 'float32')\n",
    "\n",
    "X_train_bow = np.stack(list(map(text_to_bow, texts_train)))\n",
    "X_test_bow = np.stack(list(map(text_to_bow, texts_test)))\n",
    "\n",
    "# Small check that everything is done properly if you are using local bow implementation\n",
    "k_max = len(set(' '.join(texts_train).split()))\n",
    "assert X_train_bow.shape == (len(texts_train), min(k, k_max))\n",
    "assert X_test_bow.shape == (len(texts_test), min(k, k_max))\n",
    "assert np.all(X_train_bow[5:10].sum(-1) == np.array([len(s.split()) for s in  texts_train[5:10]]))\n",
    "assert len(bow_vocabulary) <= min(k, k_max)\n",
    "assert X_train_bow[65, bow_vocabulary.index('!')] == texts_train[65].split().count('!')\n",
    "\n",
    "\n",
    "bow_model = LogisticRegression(max_iter=1500).fit(X_train_bow, y_train)\n",
    "\n",
    "out_dict = visualize_and_save_results(bow_model, 'bow_log_reg_sklearn', X_train_bow, X_test_bow, y_train, y_test, out_dict)\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gSg1inPqv5VR"
   },
   "source": [
    "Результаты неплохие, но явно видно переобучение. Этот вывод можно сделать судя по значительному превосходству качества (AUC ROC) на train выборке относительно test. Более того, на обучающей выборке качество стремится к единице, в то время как на отложенной – значительно ниже, т.е. модель уловила множество зависимостей, свойственных лишь обучающей выборке. Базово проблема переобучения рассматривалась в [лекции №3](https://youtu.be/Ql00acFsEhE). Более подробно она еще не раз встретится при дальнейшем прохождении курса.\n",
    "\n",
    "В данной задаче с переобучением мы разберемся в дальнейшем. Сейчас же реализуйте решение на основе логистической регрессии, но уже используя PyTorch. В результате вам должна быть доступна обученная модель, предсказывающая вероятности для двух классов. Качество на тестовой выборке должно не уступать логистической регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YRN4ofOgv5VR",
    "outputId": "3e81e921-5166-4612-8476-f4bb041ee6e1"
   },
   "outputs": [],
   "source": [
    "model = # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HLx_3tOCv5VR"
   },
   "source": [
    "Не забывайте о функциях потерь: `nn.CrossEntropyLoss` объединяет в себе `LogSoftMax` и `NLLLoss`. Также не забывайте о необходимости перенести тензоры на используемый `device`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W7dcCGLsv5VS"
   },
   "outputs": [],
   "source": [
    "loss_function = # your code here\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CK7iew17v5VS"
   },
   "outputs": [],
   "source": [
    "X_train_bow_torch = # your code here\n",
    "X_test_bow_torch = # your code here\n",
    "\n",
    "y_train_torch = # your code here\n",
    "y_test_torch = # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция ниже поможет с обучением модели. Часть кода необходимо реализовать самостоятельно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K4GGcyXYv5VT"
   },
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    opt,\n",
    "    X_train_torch,\n",
    "    y_train_torch,\n",
    "    X_val_torch,\n",
    "    y_val_torch,\n",
    "    n_iterations=500,\n",
    "    batch_size=32,\n",
    "    show_plots=True,\n",
    "    eval_every=50\n",
    "):\n",
    "    train_loss_history = []\n",
    "    train_acc_history = []\n",
    "    val_loss_history = []\n",
    "    val_acc_history = []\n",
    "\n",
    "    local_train_loss_history = []\n",
    "    local_train_acc_history = []\n",
    "    for i in range(n_iterations):\n",
    "\n",
    "        # sample batch_size random observations\n",
    "        ix = np.random.randint(0, len(X_train_torch), batch_size)\n",
    "        x_batch = X_train_torch[ix]\n",
    "        y_batch = y_train_torch[ix]\n",
    "\n",
    "        # predict log-probabilities or logits\n",
    "        y_predicted = # your code here\n",
    "        \n",
    "        # compute loss, just like before\n",
    "        loss = # your code here\n",
    "\n",
    "        # compute gradients\n",
    "        # your code here\n",
    "\n",
    "        # Adam step\n",
    "        # your code here\n",
    "\n",
    "        # clear gradients\n",
    "        # your code here\n",
    "\n",
    "        local_train_loss_history.append(loss.item())\n",
    "        local_train_acc_history.append(\n",
    "            accuracy_score(\n",
    "                y_batch.to('cpu').detach().numpy(),\n",
    "                y_predicted.to('cpu').detach().numpy().argmax(axis=1)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if i % eval_every == 0:\n",
    "            train_loss_history.append(np.mean(local_train_loss_history))\n",
    "            train_acc_history.append(np.mean(local_train_acc_history))\n",
    "            local_train_loss_history, local_train_acc_history = [], []\n",
    "\n",
    "            predictions_val = model(X_val_torch)\n",
    "            val_loss_history.append(loss_function(predictions_val, y_val_torch).to('cpu').detach().item())\n",
    "\n",
    "            acc_score_val = accuracy_score(y_val_torch.cpu().numpy(), predictions_val.to('cpu').detach().numpy().argmax(axis=1))\n",
    "            val_acc_history.append(acc_score_val)\n",
    "\n",
    "            if show_plots:\n",
    "                display.clear_output(wait=True)\n",
    "                plot_train_process(train_loss_history, val_loss_history, train_acc_history, val_acc_history)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 584
    },
    "id": "TILA0_Aiv5VU",
    "outputId": "0bb9db5b-82d8-486b-b320-6021d4f37459"
   },
   "outputs": [],
   "source": [
    "bow_nn_model = train_model(model, opt, X_train_bow_torch, y_train_torch, X_test_bow_torch, y_test_torch, n_iterations=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "out_dict = visualize_and_save_results(bow_nn_model, 'bow_nn_torch', X_train_bow_torch, X_test_bow_torch, y_train, y_test, out_dict)\n",
    "\n",
    "assert out_dict['bow_log_reg_sklearn_test'] - out_dict['bow_nn_torch_test'] < 0.01, 'AUC ROC on test data should be close to the sklearn implementation'\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEt4byBxv5VU"
   },
   "source": [
    "А теперь повторите процедуру обучения выше, но для различных значений `k` – размера словаря. В список results сохраните `AUC ROC` на тестовой части выборки для модели, обученной со словарем размера `k`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "jq9qxODpv5VU",
    "outputId": "47cf61ce-533c-46f7-b0c5-6f6f670018cb"
   },
   "outputs": [],
   "source": [
    "vocab_sizes_list = np.arange(100, 5800, 700)\n",
    "results = []\n",
    "\n",
    "for k in vocab_sizes_list:\n",
    "    # your code here\n",
    "    predicted_probas_on_test_for_k_sized_dict = None\n",
    "    assert predicted_probas_on_test_for_k_sized_dict is not None\n",
    "    auc = roc_auc_score(y_test, predicted_probas_on_test_for_k_sized_dict)\n",
    "    results.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert len(results) == len(vocab_sizes_list), 'Check the code above'\n",
    "assert min(results) >= 0.65, 'Seems like the model is not trained well enough'\n",
    "assert results[-1] > 0.84, 'Best AUC ROC should not be lower than 0.84'\n",
    "\n",
    "plt.plot(vocab_sizes_list, results)\n",
    "plt.xlabel('num of tokens')\n",
    "plt.ylabel('AUC')\n",
    "plt.grid()\n",
    "\n",
    "out_dict['bow_k_vary'] = results\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iA_3nEyHv5VV"
   },
   "source": [
    "### Задача №2: Использование TF-iDF признаков.\n",
    "\n",
    "Для векторизации текстов также можно воспользоваться TF-iDF. Это позволяет исключить из рассмотрения многие слова, не оказывающие значимого влияния при оценке непохожести текстов.\n",
    "\n",
    "Подробнее про TF-iDF можно почитать, например, [здесь](https://towardsdatascience.com/tf-idf-for-document-ranking-from-scratch-in-python-on-real-world-dataset-796d339a4089).\n",
    "Там же можно почитать о его самостоятельной реализации.\n",
    "\n",
    "Ваша задача: векторизовать тексты используя TF-iDF (или `TfidfVectorizer` из `sklearn`, или реализовав его самостоятельно) и построить классификатор с помощью PyTorch, аналогичный задаче №1.\n",
    "\n",
    "Затем также оцените качество классификации по AUC ROC для различных размеров словаря.\n",
    "\n",
    "Качество классификации должно быть не ниже 0.86 AUC ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "THMktAtZNAqP"
   },
   "outputs": [],
   "source": [
    "X_train_tfidf = # your code here\n",
    "X_test_tfidf = # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xHbOlK1dyws8",
    "outputId": "d19d123a-9232-4df5-b743-29e2181144d2"
   },
   "outputs": [],
   "source": [
    "model = # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 584
    },
    "id": "fioSJacvjr2v",
    "outputId": "d5b10947-9ee2-48d9-f553-7dfd9871ec20"
   },
   "outputs": [],
   "source": [
    "loss_function = # your code here\n",
    "opt = # your code here\n",
    "\n",
    "model_tf_idf = train_model(model, opt, X_train_tfidf_torch, y_train_torch, X_test_tfidf_torch, y_test_torch, n_iterations=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "out_dict = visualize_and_save_results(model_tf_idf, 'tf_idf_nn_torch', X_train_tfidf_torch, X_test_tfidf_torch, y_train, y_test, out_dict)\n",
    "\n",
    "assert out_dict['tf_idf_nn_torch_test'] >= out_dict['bow_nn_torch_test'], 'AUC ROC on test data should be better or close to BoW for TF-iDF features'\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично задаче №1 повторите процедуру обучения для различных значений `k` – размера словаря и сохраните `AUC ROC` на тестовой части выборки в список `results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_sizes_list = np.arange(100, 5800, 700)\n",
    "results = []\n",
    "\n",
    "for k in vocab_sizes_list:\n",
    "    # your code here\n",
    "    predicted_probas_on_test_for_k_sized_dict = None\n",
    "    assert predicted_probas_on_test_for_k_sized_dict is not None\n",
    "    auc = roc_auc_score(y_test, predicted_probas_on_test_for_k_sized_dict)\n",
    "    results.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert len(results) == len(vocab_sizes_list), 'Check the code above'\n",
    "assert min(results) >= 0.65, 'Seems like the model is not trained well enough'\n",
    "assert results[-1] > 0.85, 'Best AUC ROC for TF-iDF should not be lower than 0.84'\n",
    "\n",
    "plt.plot(vocab_sizes_list, results)\n",
    "plt.xlabel('num of tokens')\n",
    "plt.ylabel('AUC')\n",
    "plt.grid()\n",
    "\n",
    "out_dict['tf_idf_k_vary'] = results\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uo-aLAItv5VW"
   },
   "source": [
    "### Задача №3: Сравнение с Наивным Байесовским классификатором.\n",
    "\n",
    "Классические модели все еще способны показать хороший результат во многих задачах. Обучите наивный байесовский классификатор на текстах, векторизованных с помощью BoW и TF-iDF и сравните результаты с моделями выше.\n",
    "\n",
    "*Комментарий: обращаем ваше внимание, необходимо выбрать подходящее к данной задаче априорное распределение для признаков, т.е. выбрать верную версию классификатора из `sklearn`: `GaussianNB`, `MultinomialNB`, `ComplementNB`, `BernoulliNB`, `CategoricalNB`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "f5Hy-mJnW5Hc",
    "outputId": "e1ebb8e4-cec1-4d49-bc9b-28eff714ea78"
   },
   "outputs": [],
   "source": [
    "clf_nb_bow = # your code here\n",
    "\n",
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "out_dict = visualize_and_save_results(clf_nb_bow, 'bow_nb_sklearn', X_train_bow, X_test_bow, y_train, y_test, out_dict)\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_nb_tfidf = # your code here\n",
    "\n",
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "out_dict = visualize_and_save_results(clf_nb_tfidf, 'tf_idf_nb_sklearn', X_train_tfidf, X_test_tfidf, y_train, y_test, out_dict)\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert out_dict['tf_idf_nb_sklearn_test'] > out_dict['bow_nb_sklearn_test'],' TF-iDF results should be better'\n",
    "assert out_dict['tf_idf_nb_sklearn_test'] > 0.86, 'TF-iDF Naive Bayes score should be above 0.86'\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvqsaoedv5VW"
   },
   "source": [
    "### Задача №4: Использование предобученных эмбеддингов\n",
    "\n",
    "Наконец, воспользуемся предобученными эмбеддингами из библиотеки `gensim`. В нем доступно несколько эмбеддингов, предобученных на различных корпусах текстов. Полный список можно найти [здесь](https://radimrehurek.com/gensim/models/word2vec.html#pretrained-models). Напоминаем, что лучше использовать те эмбеддинги, которые были обучены на текстах похожей структуры.\n",
    "\n",
    "Ваша задача: обучить модель (достаточно логистической регрессии или же двуслойной неронной сети), используя усредненный эмбеддинг для всех токенов в отзыве, добиться качества не хуже, чем с помощью BoW/TF-iDF и снизить степень переобучения (разницу между AUC ROC на обучающей и тестовой выборках)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DP5td5Ivv5VW",
    "outputId": "8278e048-9676-4ba2-d76b-608f2b321bad"
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "gensim_embedding_model = api.load(# your code here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sC8wyIqY6Ce9"
   },
   "outputs": [],
   "source": [
    "def text_to_average_embedding(text, gensim_embedding_model):\n",
    "    # your code here\n",
    "    return embedding_for_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yZ8-03TIJNjz"
   },
   "outputs": [],
   "source": [
    "X_train_emb = [text_to_average_embedding(text, gensim_embedding_model) for text in texts_train]\n",
    "X_test_emb = [text_to_average_embedding(text, gensim_embedding_model) for text in texts_test]\n",
    "\n",
    "assert len(X_train_emb[0]) == gensim_embedding_model.vector_size, 'Seems like the embedding shape is wrong'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Gw5B5JJ7Z1y"
   },
   "outputs": [],
   "source": [
    "X_train_emb_torch = # your code here\n",
    "X_test_emb_torch = # your code here\n",
    "\n",
    "y_train_torch = # your code here\n",
    "y_test_torch = # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6yQ2zL0bjgcD",
    "outputId": "d0f09b05-16a5-4027-d9ee-2a537621496a"
   },
   "outputs": [],
   "source": [
    "model = # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 584
    },
    "id": "IP-Be_CRHI1f",
    "outputId": "9f6b1aca-a550-48c1-b041-29d43c239138"
   },
   "outputs": [],
   "source": [
    "loss_function = # your code here\n",
    "opt = # your code here\n",
    "\n",
    "model = train_model(model, opt, X_train_emb_torch, y_train_torch, X_test_emb_torch, y_test_torch, n_iterations=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "out_dict = visualize_and_save_results(model, 'emb_nn_torch', X_train_emb_torch, X_test_emb_torch, y_train, y_test, out_dict)\n",
    "assert out_dict['emb_nn_torch_test'] > 0.87, 'AUC ROC on test data should be better than 0.86'\n",
    "assert out_dict['emb_nn_torch_train'] - out_dict['emb_nn_torch_test'] < 0.1, 'AUC ROC on test and train data should not be different more than by 0.1'\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hohtOwysavfv"
   },
   "source": [
    "### Сдача задания\n",
    "Запустите код ниже для генерации посылки и сдайте на проверку файл `submission_dict_101.npy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o-lidlX4a_mM"
   },
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "np.save('submission_dict_101.npy', out_dict, allow_pickle=True)\n",
    "print('File saved to `submission_dict_101.npy`')\n",
    "# __________end of block__________"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP_hw01_texts.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Py3 Research",
   "language": "python",
   "name": "py3_research_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
