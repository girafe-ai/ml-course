{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ml-mipt advanced course\n",
    "# Homework 4: Convolutional VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torchvision\n",
    "import tqdm\n",
    "from matplotlib import cm\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from scipy.stats import norm\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook accompanies the [week15] practice. Refer to the classwork for more details.\n",
    "\n",
    "\n",
    "Your last and ultimate task is to implement and train __Convolutional Conditional VAE__. Simple VAE is available in week 15. For details about conditional VAE one can refer to [week 15 lecture](https://github.com/girafe-ai/ml-mipt/tree/advanced/week15_generative) or [this habr post (ru)](https://habr.com/ru/post/331664/)\n",
    "\n",
    "If it seems too easy, you can use [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset instead of MNIST.\n",
    "\n",
    "The code in general duplicates the one from the in-class practice. \n",
    "\n",
    "Do not forget to __use GPU acceleration during training__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Currently you are using device:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's dangerous to walk alone. Take these ;)\n",
    "\n",
    "\n",
    "class Rescale(object):\n",
    "    def __call__(self, image):\n",
    "        image = image - image.min()\n",
    "        image = image / image.max()\n",
    "\n",
    "        return image\n",
    "\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.flatten(x, start_dim=1, end_dim=-1)\n",
    "\n",
    "\n",
    "class RestoreShape(nn.Module):\n",
    "    def __init__(self, initial_shape):\n",
    "        super().__init__()\n",
    "        self.initial_shape = initial_shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view([-1] + list(self.initial_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Data loading stuff is done for you ;)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_transformations = transforms.Compose([transforms.ToTensor(), Rescale()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "SHUFFLE_DATASET = True\n",
    "NUM_DATALOADER_WORKERS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=torchvision.datasets.MNIST(\n",
    "        root=data_root, train=True, transform=mnist_transformations, download=True\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=SHUFFLE_DATASET,\n",
    "    num_workers=NUM_DATALOADER_WORKERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=torchvision.datasets.MNIST(\n",
    "        root=data_root, train=False, transform=mnist_transformations\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=SHUFFLE_DATASET,\n",
    "    num_workers=NUM_DATALOADER_WORKERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The code below is simple VAE. Your task is to make in convolutional (both encoder and decoder) and add class label information.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalCVAE(nn.Module):\n",
    "    def __init__(self, intermediate_dims, latent_dim, input_shape):\n",
    "        super().__init__()\n",
    "        self.register_buffer('_initial_mu', torch.zeros((latent_dim)))\n",
    "        self.register_buffer('_initial_sigma', torch.ones((latent_dim)))\n",
    "\n",
    "        self.latent_distribution = torch.distributions.normal.Normal(\n",
    "            loc=self._initial_mu, scale=self._initial_sigma\n",
    "        )\n",
    "        input_dim = np.prod(input_shape)\n",
    "        self.encoder = nn.Sequential(\n",
    "            *[\n",
    "                Flatten(),\n",
    "                nn.Linear(input_dim, intermediate_dims[0]),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(intermediate_dims[0]),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(intermediate_dims[0], intermediate_dims[1]),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(intermediate_dims[1]),\n",
    "                nn.Dropout(0.3),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # YOUR CODE HERE: define mu and sigma\n",
    "        self.mu_repr = None\n",
    "        self.log_sigma_repr = None\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            *[\n",
    "                nn.Linear(latent_dim, intermediate_dims[1]),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.BatchNorm1d(intermediate_dims[1]),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(intermediate_dims[1], intermediate_dims[0]),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.BatchNorm1d(intermediate_dims[0]),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(intermediate_dims[0], input_dim),\n",
    "                nn.Sigmoid(),\n",
    "                RestoreShape(input_shape),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def _encode(self, x):\n",
    "        latent_repr = self.encoder(x)\n",
    "        mu_values = self.mu_repr(latent_repr)\n",
    "        log_sigma_values = self.log_sigma_repr(latent_repr)\n",
    "        return mu_values, log_sigma_values, latent_repr\n",
    "\n",
    "    def _reparametrize(self, sample, mu_values, log_sigma_values):\n",
    "        # YOUR CODE HERE: reparametrize sample\n",
    "        latent_sample = None\n",
    "        return latent_sample\n",
    "\n",
    "    def forward(self, x, raw_sample=None):\n",
    "        mu_values, log_sigma_values, latent_repr = self._encode(x)\n",
    "\n",
    "        if raw_sample is None:\n",
    "            raw_sample = torch.randn_like(mu_values)\n",
    "\n",
    "        latent_sample = self._reparametrize(raw_sample, mu_values, log_sigma_values)\n",
    "\n",
    "        reconstructed_repr = self.decoder(latent_sample)\n",
    "\n",
    "        return reconstructed_repr, latent_sample, mu_values, log_sigma_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digits(*args):\n",
    "    args = [x.squeeze() for x in args]\n",
    "    n = min([x.shape[0] for x in args])\n",
    "\n",
    "    fig = plt.figure(figsize=(2 * n, 2 * len(args)))\n",
    "    for j in range(n):\n",
    "        for i in range(len(args)):\n",
    "            ax = plt.subplot(len(args), n, i * n + j + 1)\n",
    "            plt.imshow(args[i][j])\n",
    "            plt.gray()\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch = next(iter(train_loader))\n",
    "example_batch = [x.to(device) for x in example_batch]\n",
    "example_x = example_batch[0][0]\n",
    "\n",
    "model = ConvolutionalCVAE([256, 128], 2, example_x.shape).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_func = torch.nn.modules.loss.BCELoss()\n",
    "\n",
    "reconstructed_repr, latent_sample, mu_values, log_sigma_values = model(\n",
    "    example_batch[0][:15].to(device)\n",
    ")\n",
    "\n",
    "summary(model, example_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: define kl_loss\n",
    "kl_loss = None\n",
    "kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_predictions(model, test_loader):\n",
    "    model.eval()\n",
    "    reconstructed_repr_list, latent_samples_list, mu_values_list, log_sigma_values_list = [], [], [], []\n",
    "    for test_batch in tqdm.tqdm_notebook(test_loader, leave=False):\n",
    "        out = model(test_batch[0].to(device))\n",
    "        reconstructed_repr, latent_sample, mu_values, log_sigma_values = [x.detach().cpu() for x in out]\n",
    "        reconstructed_repr_list.append(reconstructed_repr)\n",
    "        latent_samples_list.append(latent_sample)\n",
    "        mu_values_list.append(mu_values)\n",
    "        log_sigma_values_list.append(log_sigma_values)\n",
    "    return [\n",
    "        torch.cat(_list, dim=0)\n",
    "        for _list in [reconstructed_repr_list, latent_samples_list, mu_values_list, log_sigma_values_list]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_repr, latent_sample, mu_values, log_sigma_values = get_test_predictions(\n",
    "    model, test_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 15  # to generate image with 15x15 examples\n",
    "digit_size = 28\n",
    "latent_dim = 2\n",
    "\n",
    "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "\n",
    "\n",
    "def draw_manifold(model, show=True):\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "    for i, yi in enumerate(grid_x):\n",
    "        for j, xi in enumerate(grid_y):\n",
    "            z_sample = np.zeros((1, latent_dim))\n",
    "            z_sample[:, :2] = np.array([[xi, yi]])\n",
    "\n",
    "            z_torch = torch.from_numpy(z_sample).type(torch.FloatTensor).to(device)\n",
    "\n",
    "            x_decoded = model.decoder(z_torch).detach().cpu().numpy()\n",
    "            digit = x_decoded[0].squeeze()\n",
    "            figure[\n",
    "                i * digit_size : (i + 1) * digit_size, j * digit_size : (j + 1) * digit_size\n",
    "            ] = digit\n",
    "    if show:\n",
    "        plt.figure(figsize=(15, 15))\n",
    "        plt.imshow(figure, cmap='Greys_r')\n",
    "        # plt.grid(None)\n",
    "        ax = plt.gca()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        plt.show()\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "_img = draw_manifold(model, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch):\n",
    "    # Saving manifold and z distribution to build plots and animation afterwards\n",
    "    figure = draw_manifold(model, show=False)\n",
    "    reconstructed_repr, latent_sample, mu_values, log_sigma_values = get_test_predictions(\n",
    "        model, test_loader\n",
    "    )\n",
    "    return figure, reconstructed_repr, latent_sample, mu_values, log_sigma_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs):\n",
    "    epochs, figs, latent_distrs = [], [], []\n",
    "    for epoch_num in tqdm.tnrange(num_epochs):\n",
    "        model.train()\n",
    "        loss_accumulator = 0.0\n",
    "        bce_acc = 0.0\n",
    "        kl_acc = 0.0\n",
    "        for batch_x, batch_label in tqdm.tqdm_notebook(train_loader, leave=False):\n",
    "            batch_x = batch_x.to(device)\n",
    "            predictions, latent, mu_values, log_sigma_values = model(batch_x)\n",
    "\n",
    "            # YOUR CODE HERE: same kl_loss as above\n",
    "            kl_loss = None\n",
    "            bce_loss = 28 * 28 * loss_func(predictions, batch_x)\n",
    "            loss = (bce_loss + kl_loss) / 2.0 / 28.0 / 28.0\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "            loss_accumulator += loss.item() / (len(train_loader.dataset))\n",
    "            bce_acc += bce_loss.item() / (len(train_loader.dataset))\n",
    "            kl_acc += kl_loss.item() / (len(train_loader.dataset))\n",
    "\n",
    "        if epoch_num % 5 == 0:\n",
    "            print(\n",
    "                'Epoch num: {}\\nTraining loss={:.4f}, KL divergence={:.4f}, BCE Loss={:.4f}'.format(\n",
    "                    epoch_num, loss_accumulator, kl_acc, bce_acc\n",
    "                )\n",
    "            )\n",
    "            model.eval()\n",
    "            (\n",
    "                figure,\n",
    "                reconstructed_repr_test,\n",
    "                latent_sample_test,\n",
    "                mu_values_test,\n",
    "                log_sigma_values_test,\n",
    "            ) = on_epoch_end(epoch_num)\n",
    "            epochs.append(epoch_num)\n",
    "            figs.append(figure)\n",
    "            latent_distrs.append((mu_values_test, log_sigma_values_test))\n",
    "    return epochs, figs, latent_distrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs, figs, latent_distrs = train(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = []\n",
    "for b in test_loader:\n",
    "    test_labels.append(b[1])\n",
    "test_labels = torch.cat(test_labels, dim=0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path('./my_figs').mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "def make_2d_figs_gif(figs, epochs, fname, fig):\n",
    "    norm = matplotlib.colors.Normalize(vmin=0, vmax=1, clip=False)\n",
    "    im = plt.imshow(np.zeros((28, 28)), cmap='Greys_r', norm=norm)\n",
    "    plt.grid(None)\n",
    "    plt.title(\"Epoch: \" + str(epochs[0]))\n",
    "\n",
    "    def update(i):\n",
    "        im.set_array(figs[i])\n",
    "        im.axes.set_title(\"Epoch: \" + str(epochs[i]))\n",
    "        im.axes.get_xaxis().set_visible(False)\n",
    "        im.axes.get_yaxis().set_visible(False)\n",
    "        return im\n",
    "\n",
    "    anim = FuncAnimation(fig, update, frames=range(len(figs)), interval=100)\n",
    "    anim.save(fname, dpi=80, writer='imagemagick')\n",
    "\n",
    "\n",
    "def make_2d_scatter_gif(zs, epochs, c, fname, fig):\n",
    "    im = plt.scatter(zs[0][:, 0], zs[0][:, 1], c=c, cmap=cm.coolwarm)  # noqa: F841\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Epoch: \" + str(epochs[0]))\n",
    "\n",
    "    def update(i):\n",
    "        fig.clear()\n",
    "        im = plt.scatter(zs[i][:, 0], zs[i][:, 1], c=c, cmap=cm.coolwarm)\n",
    "        im.axes.set_title(\"Epoch: \" + str(epochs[i]))\n",
    "        im.axes.set_xlim(-5, 5)\n",
    "        im.axes.set_ylim(-5, 5)\n",
    "        return im\n",
    "\n",
    "    anim = FuncAnimation(fig, update, frames=range(len(zs)), interval=150)\n",
    "    anim.save(fname, dpi=80, writer='imagemagick')\n",
    "\n",
    "\n",
    "make_2d_figs_gif(figs, epochs, \"./my_figs/manifold2.gif\", plt.figure(figsize=(10, 10)))\n",
    "make_2d_scatter_gif(\n",
    "    [x[0].numpy() for x in latent_distrs],\n",
    "    epochs,\n",
    "    test_labels,\n",
    "    \"./my_figs/z_distr2.gif\",\n",
    "    plt.figure(figsize=(10, 10)),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find your brand gifs in `./my_figs/` directory ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally you can also implement GAN for this task. Good luck!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
