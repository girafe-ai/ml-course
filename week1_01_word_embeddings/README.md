Visualizing and building embeddings:
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/girafe-ai/ml-mipt/blob/22f_binpord/week1_01_word_embeddings/practice_word_embeddings.ipynb)

Solved version:
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/girafe-ai/ml-mipt/blob/22f_binpord/week1_01_word_embeddings/practice_word_embeddings_solved.ipynb)

Further readings:

1. Great resource by Lena Voita (direct link to Word Embeddings explanation):
   https://lena-voita.github.io/nlp_course/word_embeddings.html
2. Word2vec tutorial:
   http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/
3. Beautiful post by Jay Alammar:
   http://jalammar.github.io/illustrated-word2vec/
